# Multimodal-Data-Generation-Resources

## Review

**Data-centric artificial intelligence: A survey.**<br>
*D Zha, ZP Bhat, KH Lai, F Yang, Z Jiang, S Zhong, X Hu.*<br>
arXiv:2303.10158, 2023.
[[ArXiv](https://arxiv.org/pdf/2303.10158)]

**Will we run out of data? an analysis of the limits of scaling datasets in machine learning.**<br>
*P Villalobos, J Sevilla, L Heim, T Besiroglu, M Hobbhahn, A Ho.*<br>
arXiv:2211.04325, 2022.
[[ArXiv](https://arxiv.org/pdf/2211.04325)]

**From concept to implementation: The data-centric development process for AI in industry.**<br>
*PP Luley, JM Deriu, P Yan, GA Schatte, T Stadelmann.*<br>
2023 10th IEEE Swiss Conference on Data Science (SDS), 2023.
[[Paper](https://digitalcollection.zhaw.ch/bitstream/11475/28148/1/2023_Luley-etal_Data-centric-development-process-for-AI-in-industry_v2.pdf)]

## LLMs DataSets Resources

**Datasets for Large Language Models: A Comprehensive Survey.**<br>
*Y Liu, J Cao, C Liu, K Ding, et al.*<br>
ArXiv, 2024.
[[ArXiv](https://arxiv.org/pdf/2402.18041)]
[[Github](https://github.com/yfzhang114/Awesome-Multimodal-Large-Language-Models)]

**LLM Datasets**<br>
*High-quality datasets, tools, and concepts for LLM fine-tuning.*<br>
[[Github](https://github.com/mlabonne/llm-datasets)]

## Data Quality

**A Survey on Data Selection for Language Models.**<br>
*A Albalak, Y Elazar, et al.*<br>
ArXiv, 2024.
[[ArXiv](http://arxiv.org/pdf/2402.16827)]

**Dataperf: Benchmarks for data-centric ai development.**<br>
*M Mazumder, C Banbury, X Yao, et al.*<br>
NeurIPS, 2024.
[[ArXiv](https://proceedings.neurips.cc/paper_files/paper/2023/file/112db88215e25b3ae2750e9eefcded94-Paper-Datasets_and_Benchmarks.pdf)]
[[Github](https://github.com/mlcommons/dataperf)]

**Alpagasus: Training a better alpaca with fewer data.**<br>
*L Chen, S Li, J Yan, H Wang, K Gunaratna, V Yadav, Z Tang, V Srinivasan, T Zhou, H Huang, et al.*<br>
arXiv:2307.08701, 2023.
[[ArXiv](https://arxiv.org/pdf/2307.08701)]
[[Github](https://lichang-chen.github.io/AlpaGasus/)]

**Longwanjuan: Towards systematic measurement for long text quality.**<br>
*K Lv, X Liu, Q Guo, H Yan, C He, X Qiu, D Lin.*<br>
arxiv:2402.13583, 2024.
[[ArXiv](https://arxiv.org/pdf/2402.13583)]
[[Github](https://github.com/OpenLMLab/LongWanjuan)]

## Training DataSets Generation

**Self-alignment with instruction backtranslation.**<br>
*X Li, P Yu, C Zhou, T Schick, L Zettlemoyer, O Levy, J Weston, M Lewis.*<br>
 arXiv:2308.06259, 2023.
[[Github](https://arxiv.org/pdf/2308.06259)]

**Large language model as attributed training data generator: A tale of diversity and bias.**<br>
*Y Yu, Y Zhuang, J Zhang, Y Meng, AJ Ratner, R Krishna, J Shen, C Zhang.*<br>
Advances in Neural Information Processing Systems, 2024.
[[Paper](https://proceedings.neurips.cc/paper_files/paper/2023/file/ae9500c4f5607caf2eff033c67daa9d7-Paper-Datasets_and_Benchmarks.pdf)]
[[Github](https://github.com/yueyu1030/AttrPrompt)]

**Automatically Generating Numerous Context-Driven SFT Data for LLMs across Diverse Granularity.**<br>
*S Quan.*<br>
arXiv:2405.16579, 2024.
[[Paper](https://arxiv.org/pdf/2405.16579)]
[[Github](https://github.com/quanshr/AugCon)]

**Scaling Synthetic Data Creation with 1,000,000,000 Personas.**<br>
*X Chan, X Wang, D Yu, H Mi, D Yu.*<br>
arXiv:2406.20094, 2024.
[[Paper](https://arxiv.org/pdf/2406.20094?trk=public_post_comment-text)]
[[Github](https://github.com/tencent-ailab/persona-hub)]

## Test DataSets Generation

### Language

**Dyval: Graph-informed dynamic evaluation of large language models.**<br>
*K Zhu, J Chen, J Wang, NZ Gong, D Yang, X Xie.*<br>
arXiv:2309.17167, 2023.
[[ArXiv](https://arxiv.org/pdf/2309.17167)]
[[Github](https://github.com/microsoft/promptbench)]

**Worldsense: A synthetic benchmark for grounded reasoning in large language models.**<br>
*Y Benchekroun, M Dervishi, M Ibrahim, JB Gaya, X Martinet, G Mialon, T Scialom, E Dupoux, et al.*<br>
arXiv:2311.15930, 2023.
[[ArXiv](https://arxiv.org/pdf/2311.15930)]
[[Github](https://github.com/facebookresearch/worldsense)]

**S3eval: A synthetic, scalable, systematic evaluation suite for large language models.**<br>
*F Lei, Q Liu, Y Huang, S He, J Zhao, K Liu.*<br>
arXiv:2310.15147, 2023.
[[ArXiv](https://arxiv.org/pdf/2310.15147)]
[[Github](https://github.com/lfy79001/S3Eval)]

### Multimodal

**Task Me Anything.**<br>
*J Zhang, W Huang, Z Ma, O Michel, D He, et al.*<br>
arXiv, 2024.
[[ArXiv](https://arxiv.org/pdf/2406.11775)]
[[Github](https://www.task-me-anything.org/)]

**Needle In A Video Haystack: A Scalable Synthetic Framework for Benchmarking Video MLLMs.**<br>
*Z Zhao, H Lu, Y Huo, Y Du, T Yue, L Guo, B Wang, W Chen, J Liu.*<br>
arXiv:2406.09367, 2024.
[[ArXiv](https://arxiv.org/pdf/2406.09367)]
[[Github](https://github.com/joez17/VideoNIAH)]

## Interaction DataSets Generation

### Prompt Optimization

**Efficient Prompting Methods for Large Language Models: A Survey.**<br>
*K Chang, S Xu, C Wang, Y Luo, T Xiao, J Zhu.*<br>
arXiv:2404.01077, 2024.
[[ArXiv](https://arxiv.org/pdf/2404.01077)]

**Prompt Optimization with Human Feedback.**<br>
*X Lin, Z Dai, A Verma, SK Ng, P Jaillet, BKH Low.*<br>
arXiv:2405.17346, 2024.
[[ArXiv](https://arxiv.org/pdf/2405.17346)]
[[Github](https://arxiv.org/pdf/2405.17346)]

**PROPANE: Prompt design as an inverse problem.**<br>
*R Melamed, LH McCabe, T Wakhare, Y Kim, HH Huang, E Boix-Adsera.*<br>
arXiv:2311.07064, 2023.
[[ArXiv](https://arxiv.org/pdf/2311.07064)]

