# Multimodal-Data-Generation-Resources

## Review

**Data-centric artificial intelligence: A survey.**<br>
*D Zha, ZP Bhat, KH Lai, F Yang, Z Jiang, S Zhong, X Hu.*<br>
arXiv:2303.10158, 2023.
[[ArXiv](https://arxiv.org/pdf/2303.10158)]

**Will we run out of data? an analysis of the limits of scaling datasets in machine learning.**<br>
*P Villalobos, J Sevilla, L Heim, T Besiroglu, M Hobbhahn, A Ho.*<br>
arXiv:2211.04325, 2022.
[[ArXiv](https://arxiv.org/pdf/2211.04325)]

**From concept to implementation: The data-centric development process for AI in industry.**<br>
*PP Luley, JM Deriu, P Yan, GA Schatte, T Stadelmann.*<br>
2023 10th IEEE Swiss Conference on Data Science (SDS), 2023.
[[Paper](https://digitalcollection.zhaw.ch/bitstream/11475/28148/1/2023_Luley-etal_Data-centric-development-process-for-AI-in-industry_v2.pdf)]

## LLMs DataSets Resources

**Datasets for Large Language Models: A Comprehensive Survey.**<br>
*Y Liu, J Cao, C Liu, K Ding, et al.*<br>
ArXiv, 2024.
[[ArXiv](https://arxiv.org/pdf/2402.18041)]
[[Github](https://github.com/yfzhang114/Awesome-Multimodal-Large-Language-Models)]

**LLM Datasets**<br>
*High-quality datasets, tools, and concepts for LLM fine-tuning.*<br>
[[Github](https://github.com/mlabonne/llm-datasets)]

## Data Quality

**A Survey on Data Selection for Language Models.**<br>
*A Albalak, Y Elazar, et al.*<br>
ArXiv, 2024.
[[ArXiv](http://arxiv.org/pdf/2402.16827)]

**Dataperf: Benchmarks for data-centric ai development.**<br>
*M Mazumder, C Banbury, X Yao, et al.*<br>
NeurIPS, 2024.
[[ArXiv](https://proceedings.neurips.cc/paper_files/paper/2023/file/112db88215e25b3ae2750e9eefcded94-Paper-Datasets_and_Benchmarks.pdf)]
[[Github](https://github.com/mlcommons/dataperf)]

## Training DataSets Generation

**Self-alignment with instruction backtranslation.**<br>
*X Li, P Yu, C Zhou, T Schick, L Zettlemoyer, O Levy, J Weston, M Lewis.*<br>
 arXiv:2308.06259, 2023.
[[Github](https://arxiv.org/pdf/2308.06259)]

**Large language model as attributed training data generator: A tale of diversity and bias.**<br>
*Y Yu, Y Zhuang, J Zhang, Y Meng, AJ Ratner, R Krishna, J Shen, C Zhang.*<br>
Advances in Neural Information Processing Systems, 2024.
[[Paper](https://proceedings.neurips.cc/paper_files/paper/2023/file/ae9500c4f5607caf2eff033c67daa9d7-Paper-Datasets_and_Benchmarks.pdf)]
[[Github](https://github.com/yueyu1030/AttrPrompt)]

## Test DataSets Generation

**Dyval: Graph-informed dynamic evaluation of large language models.**<br>
*K Zhu, J Chen, J Wang, NZ Gong, D Yang, X Xie.*<br>
arXiv:2309.17167, 2023.
[[ArXiv](https://arxiv.org/pdf/2309.17167)]
[[Github](https://github.com/microsoft/promptbench)]

**Worldsense: A synthetic benchmark for grounded reasoning in large language models.**<br>
*Y Benchekroun, M Dervishi, M Ibrahim, JB Gaya, X Martinet, G Mialon, T Scialom, E Dupoux, et al.*<br>
arXiv:2311.15930, 2023.
[[ArXiv](https://arxiv.org/pdf/2311.15930)]
[[Github](https://github.com/facebookresearch/worldsense)]

**S3eval: A synthetic, scalable, systematic evaluation suite for large language models.**<br>
*F Lei, Q Liu, Y Huang, S He, J Zhao, K Liu.*<br>
arXiv:2310.15147, 2023.
[[ArXiv](https://arxiv.org/pdf/2310.15147)]
[[Github](https://github.com/lfy79001/S3Eval)]

## Interaction DataSets Generation

### Prompt Optimizatio

**Efficient Prompting Methods for Large Language Models: A Survey.**<br>
*K Chang, S Xu, C Wang, Y Luo, T Xiao, J Zhu.*<br>
arXiv:2404.01077, 2024.
[[ArXiv](https://arxiv.org/pdf/2404.01077)]

**Prompt Optimization with Human Feedback.**<br>
*X Lin, Z Dai, A Verma, SK Ng, P Jaillet, BKH Low.*<br>
arXiv:2405.17346, 2024.
[[ArXiv](https://arxiv.org/pdf/2405.17346)]
[[Github](https://arxiv.org/pdf/2405.17346)]



